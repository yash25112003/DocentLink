# schema_generator.py
import json
import logging
from typing import Dict, Any, Tuple, Optional

from llm_handler import _call_gemini_api # Assumes llm_handler.py is in the same path

logger = logging.getLogger(__name__)

class SchemaGenerator:
    """Generates dynamic schemas for academic content extraction based on the content itself."""

    def __init__(self):
        logger.info("SchemaGenerator initialized for dynamic, content-aware schema generation.")

    def _build_dynamic_schema_prompt(self, clean_content: str) -> str:
        """Constructs a prompt that asks the LLM to generate a schema FROM the content."""
        # Truncate content to avoid exceeding LLM token limits
        prompt = f"""
        Objective: Analyze the provided text from an academic's webpage and generate a comprehensive JSON schema that can capture all the information present. The goal is to create a schema that, when populated, will result in a 100% complete representation of the source text.

        Source Text:
        ---
        {clean_content[:8000]}
        ---

        Instructions for Schema Generation:
        1.  **Analyze the Entire Text**: Read through the text to identify all distinct sections and data points. This includes personal details, biography, mission statements, research interests, publications, educational background, teaching roles, awards, grants, contact information, etc.
        2.  **Design a Nested Structure**: Create a JSON schema with nested objects and lists to represent the data logically.
            * `personal_info`: An object for name, title, email, phone, office, website links, department, and institution.
            * `biography`: A string that can hold the main descriptive text.
            * `research`: An object containing `interests` (list of strings), an `overview`, and a list of `projects`.
            * `publications`: A list of objects. Each object should have fields like `title`, `authors` (list of strings), `venue`, `year` (integer), `url`, and `description` or `abstract`.
            * `education`: A list of objects for degrees. Each object should have `degree`, `field`, `institution`, and `year`.
            * `teaching`: An object describing teaching roles and a list of `courses`.
            * `awards_and_honors`: A list of objects, each with `title`, `organization`, and `year`.
        3.  **Be Comprehensive**: If you identify other structured data (e.g., patents, affiliations, service), create appropriate keys and structures for them.
        4.  **Use Appropriate Data Types**: Use "string", "integer", "list[string]", "object", and "list[object]".
        5.  **Output Format**: Respond with ONLY the JSON schema object. Do not wrap it in markdown or add any explanatory text outside the JSON structure.

        Now, generate the schema for the source text provided above.
        """
        return prompt

    def generate_schema_from_content(self, clean_content: str) -> Tuple[Optional[Dict], Optional[str], Optional[str]]:
        """
        Analyzes content and uses an LLM to generate a new, dynamic schema.

        Returns:
            A tuple containing: (schema dictionary, schema version string, schema documentation string)
        """
        logger.info("Generating a new dynamic schema from content...")
        prompt = self._build_dynamic_schema_prompt(clean_content)

        llm_response_str = _call_gemini_api(prompt)

        if not llm_response_str:
            logger.error("Failed to get response from LLM for dynamic schema generation.")
            return None, None, None

        try:
            # Clean the response string
            if llm_response_str.startswith("```json"):
                llm_response_str = llm_response_str[len("```json"):].strip()
            if llm_response_str.endswith("```"):
                llm_response_str = llm_response_str[:-len("```")].strip()

            schema = json.loads(llm_response_str)
            version = "dynamic-v1.0"
            documentation = "This schema was dynamically generated by an LLM to specifically match the structure of the provided content, aiming for maximum data capture."
            logger.info("Successfully generated and parsed dynamic schema from LLM response.")
            return schema, version, documentation

        except json.JSONDecodeError as e:
            logger.error(f"Failed to decode JSON from LLM for schema generation: {e}\nRaw response was:\n{llm_response_str}")
            return None, None, None
        except Exception as e:
            logger.error(f"An unexpected error occurred during schema generation: {e}")
            return None, None, None

    def analyze_and_generate_schema(self, content: Dict[str, str]) -> Tuple[Optional[Dict], Optional[str], Optional[str]]:
        """
        Main entry point for the class, designed to be called by the processor.
        It flattens the input content and generates a dynamic schema.
        """
        full_text = "\n\n".join(f"# {key}\n{value}" for key, value in content.items() if isinstance(value, str))
        if not full_text:
            full_text = str(content)

        return self.generate_schema_from_content(full_text)